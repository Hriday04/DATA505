<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Model1 - Wine Feature Engineering and Model Training</title>
  
  <!-- Superhero theme (Bootswatch) -->  
  <style>
    body {
      font-family: monospace;
      padding: 20px;
    }
    .banner {
      background-color: #2c3e50;
      padding: 20px;
      color: #ecf0f1;
      border-radius: 10px;
      margin-bottom: 30px;
    }
    h1, h2, h3 {
      margin-top: 30px;
    }
    pre {
      background-color: #f8f9fa;
      padding: 15px;
      border-radius: 5px;
      color: #333;
      overflow-x: auto;
    }
    code {
      font-family: monospace;
    }
    .section {
      margin-bottom: 40px;
    }
  </style>
</head>

<body>

  <div class="banner">
    <h1>Model1</h1>
    <p><strong>Author:</strong> Hriday Raj</p>
    <p><strong>Date:</strong> 03/17/2025</p>
  </div>

  <h2>Wine Feature Engineering and Model Training</h2>

  <div class="section">
    <h3>Import Libraries & Load Dataset</h3>
    <pre><code>import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import cohen_kappa_score
from nltk.stem import WordNetLemmatizer
import nltk
from gensim.models import Word2Vec
from textblob import TextBlob
from nltk.sentiment import SentimentIntensityAnalyzer
from textstat import flesch_reading_ease
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

# Load dataset
path = "/Users/hridayraj/Desktop/sp25/ml/model1/model.pickle"
wine = pd.read_pickle(path)</code></pre>
  </div>

  <div class="section">
    <h3>Log Transformations</h3>
    <pre><code>wine['log_price'] = np.log1p(wine['price'])
wine['log_points'] = np.log1p(wine['points'])
wine['log_points_per_price'] = wine['log_points'] / wine['log_price']</code></pre>
  </div>

  <div class="section">
    <h3>Lemmatization & Word Count</h3>
    <pre><code>nltk.download('wordnet')
lemmatizer = WordNetLemmatizer()

def lemmatize_text(text):
    return ' '.join([lemmatizer.lemmatize(word) for word in str(text).split()])

wine['description'] = wine['description'].apply(lemmatize_text)
wine['desc_word_count'] = wine['description'].apply(lambda x: len(str(x).split()))</code></pre>
  </div>

  <div class="section">
    <h3>Word2Vec Embeddings</h3>
    <pre><code>sentences = [str(desc).split() for desc in wine['description']]
word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)

def get_doc_embedding(text):
    words = str(text).split()
    vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]
    return np.mean(vectors, axis=0) if vectors else np.zeros(100)

doc_embeddings = np.array([get_doc_embedding(desc) for desc in wine['description']])
embedding_df = pd.DataFrame(doc_embeddings, columns=[f'embedding_{i}' for i in range(doc_embeddings.shape[1])])

wine = pd.concat([wine.reset_index(drop=True), embedding_df.reset_index(drop=True)], axis=1)</code></pre>
  </div>

  <div class="section">
    <h3>Price Bucketing & Sentiment Analysis</h3>
    <pre><code>def price_bucket_func(price):
    if price < 20:
        return 'cheap'
    elif price < 50:
        return 'midrange'
    else:
        return 'expensive'

wine['price_bucket'] = wine['price'].apply(price_bucket_func)

# Sentiment Analysis using TextBlob
wine['sentiment_polarity'] = wine['description'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)
wine['sentiment_subjectivity'] = wine['description'].apply(lambda x: TextBlob(str(x)).sentiment.subjectivity)

# Sentiment Analysis using VADER
nltk.download('vader_lexicon')
sia = SentimentIntensityAnalyzer()
wine['vader_sentiment'] = wine['description'].apply(lambda x: sia.polarity_scores(str(x))['compound'])

# Readability Score
wine['readability'] = wine['description'].apply(lambda x: flesch_reading_ease(str(x)))</code></pre>
  </div>

  <div class="section">
    <h3>Encode Categorical & Impute Missing Values</h3>
    <pre><code># One-Hot Encode price_bucket
wine = pd.get_dummies(wine, columns=['price_bucket'], drop_first=True)

# Impute missing values
imputer = SimpleImputer(strategy='median')
wine[['log_price', 'log_points']] = imputer.fit_transform(wine[['log_price', 'log_points']])</code></pre>
  </div>

  <div class="section">
    <h3>Feature Scaling & Cleanup</h3>
    <pre><code>scaler = StandardScaler()
numeric_cols = [
    'log_price', 'log_points', 'log_points_per_price',
    'desc_word_count', 'sentiment_polarity',
    'sentiment_subjectivity', 'vader_sentiment', 'readability'
]
wine[numeric_cols] = scaler.fit_transform(wine[numeric_cols])

# Drop the description column (already processed)
wine = wine.drop(columns=['description'])</code></pre>
  </div>

  <div class="section">
    <h3>Train & Evaluate Model</h3>
    <pre><code># Train/Test Split
train, test = train_test_split(wine, test_size=0.2, stratify=wine['province'])

X_train = train.drop(columns=['province'])
X_test = test.drop(columns=['province'])
y_train = train['province']
y_test = test['province']

# Train KNN model
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)

# Evaluate with Cohen's Kappa Score
kappa = cohen_kappa_score(y_test, knn.predict(X_test))

print(f"Cohen's Kappa: {kappa}")</code></pre>
  </div>

</body>
</html>
